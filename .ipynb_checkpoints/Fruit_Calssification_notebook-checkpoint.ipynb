{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75922d09",
   "metadata": {},
   "source": [
    "# Implementing Feed Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c7ac9",
   "metadata": {},
   "source": [
    "First of all, we retreive the train set by using the previously implemented methods in Loading_Datasets.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2308419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ANN_Project_Assets import Loading_Datasets as ld\n",
    "\n",
    "train_set = ld.load_and_get_set(test_or_train=\"train\",\n",
    "                                feature_file_path=\"ANN_Project_Assets/Datasets/train_set_features.pkl\",\n",
    "                                label_file_path=\"ANN_Project_Assets/Datasets/train_set_labels.pkl\")\n",
    "\n",
    "layer_sizes = [len(train_set[0][0]), 150, 60, 4]  # [102, 150, 60, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b7913",
   "metadata": {},
   "source": [
    "Then, we declare the weight and bias variable; The weight and bias for between layers k and k+1 id notated by W[k] and B[k]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8591fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 4 layers, between each two consecutive layers, there needs to be a weight matrix\n",
    "W = [\n",
    "    np.random.normal(size=(layer_sizes[1], layer_sizes[0])),  # weights between layer 0 and 1, aka W[0]\n",
    "    np.random.normal(size=(layer_sizes[2], layer_sizes[1])),  # weights between layer 1 and 2, aka W[1]\n",
    "    np.random.normal(size=(layer_sizes[3], layer_sizes[2]))  # weights between layer 2 and 3, aka W[2]\n",
    "]\n",
    "\n",
    "# Initialize bias to 0, for every layer.\n",
    "B = [\n",
    "    np.zeros((layer_sizes[1], 1)),  # bias vector between layer 0 and 1, aka B[0]\n",
    "    np.zeros((layer_sizes[2], 1)),  # bias vector between layer 1 and 2, aka B[1]\n",
    "    np.zeros((layer_sizes[3], 1)),  # bias vector between layer 2 and 3, aka B[2]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8acbde",
   "metadata": {},
   "source": [
    "We would need two methods to use in the feed forwrd implementation.\n",
    "one is the activation function, here we implement the sigmoid function and use it later as the acivation function.\n",
    "the other is used for checking the labels, used to compare the calculated and actual values of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58fd5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def check_accuracy(calculated_labels, correct_labels):\n",
    "    calculated_ans = np.where(calculated_labels == np.amax(calculated_labels))\n",
    "    correct_ans = np.where(correct_labels == np.amax(correct_labels))\n",
    "\n",
    "    return calculated_ans == correct_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e3372",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be11a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07\n"
     ]
    }
   ],
   "source": [
    "def run_feed_forward():\n",
    "    data_size = 200  # number of train set elements taken from the train set\n",
    "    correct_ans_count = 0  # number of correct answers, initialized at 0\n",
    "\n",
    "    for td in train_set[:data_size]:\n",
    "        z = [\n",
    "            np.zeros((layer_sizes[0], 1)),\n",
    "            np.zeros((layer_sizes[1], 1)),\n",
    "            np.zeros((layer_sizes[2], 1)),\n",
    "            np.zeros((layer_sizes[3], 1))\n",
    "\n",
    "        ]\n",
    "\n",
    "        # values of the first layer (0th), initialized as the train data\n",
    "        z[0] = td[0]\n",
    "        np.reshape(z[0], (102, 1))\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            # for each next layer, z is calculated as discussed below\n",
    "            z[i] = sigmoid(W[i - 1] @ z[i - 1] + B[i - 1])\n",
    "\n",
    "        if check_accuracy(z[3], td[1]):\n",
    "            correct_ans_count += 1\n",
    "\n",
    "    return correct_ans_count / data_size\n",
    "\n",
    "\n",
    "print(\"Feed Forward Accuracy: \", run_feed_forward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c8108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c83da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
